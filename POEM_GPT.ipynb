{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madhusri02/Poem_Generator/blob/master/POEM_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "#for gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cVgATKoU4WM",
        "outputId": "14831729-df1b-4193-f575-25fdc249b1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfiAIhB431C5",
        "outputId": "74349372-0c23-45f9-d925-d7937ec668af"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.10/dist-packages (3.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizer\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EK-tQ2yD6CJM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# time related modules\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "# PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab.\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mrYVDQxV4g2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1c4793f0-518b-44b7-ae61-9cf3804d1f18"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13854,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 200,\n        \"samples\": [\n          95,\n          15,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13240,\n        \"samples\": [\n          \"\\r\\r\\n                    Sonnet 111: O, for my sake do you with Fortune chide,\\r\\r\\n                \",\n          \"\\r\\r\\n                    Washing the World\\r\\r\\n                \",\n          \"\\r\\r\\nfrom \\u201cAn Attempt at Jealousy\\u201d\\r\\r\\n                \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Poem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13754,\n        \"samples\": [\n          \"\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\n(To Saul Touster)\\r\\r\\n\\r\\r\\n\\r\\r\\n\\r\\r\\nI. January 22, 1932\\r\\r\\n \\r\\r\\nCould a four-year-old look out of a square sedan\\r\\r\\n(A Studebaker Six in currency green\\r\\r\\nWith wooden artillery wheels) and see a scene\\r\\r\\nOf snow, light lavender, landing on deepening blue\\r\\r\\nBuildings built out of red-violet bricks, and black\\r\\r\\nPassersby passing by over the widening white\\r\\r\\nStreets darkening blue, under a thickening white\\r\\r\\nSky suddenly undergoing sheer twilight,\\r\\r\\nAnd the yellow but whitening streetlights coming on,\\r\\r\\nAnd remember it now, though the likelihood is gone\\r\\r\\nThat it ever happened at all, and the Village is gone\\r\\r\\nThat it ever could happen in? Memory, guttering out,\\r\\r\\nApparently, finally flares up and banishes doubt.\\r\\r\\n \\r\\r\\n \\r\\r\\nII. May 29, 1941\\r\\r\\n \\r\\r\\nTring. Bells\\r\\r\\nOn grocers\\u2019 boys\\u2019 bicycles ring,\\r\\r\\nFollowed, on cue,\\r\\r\\nBy the jaunty one-note of prayers at two\\r\\r\\nNear churches; taxi horns, a-hunt,\\r\\r\\nCome in for treble; next, the tickety bass\\r\\r\\nOf chain-driven Diamond T\\u2019s, gone elephantine\\r\\r\\nAnd stove-enamelled conifer green\\r\\r\\nDown Greenwich Avenue.\\r\\r\\nOut of the Earle\\r\\r\\nI issue at half-past thirteen,\\r\\r\\nStruck, like a floral clock,\\r\\r\\nBy seasonal\\r\\r\\nManifestations: unreasonable\\r\\r\\nN.Y.U. girls out in their bobby socks\\r\\r\\nAnd rayon blouses; meek boys with their books\\r\\r\\nWho have already moulted mackinaws;Desarrolimiento of\\r\\r\\nNew chrome-green leaves; a rose,\\r\\r\\nGot, blooming, out of bed; and Mrs. Roos-\\r\\r\\nEvelt and Sarah Delano\\r\\r\\nDescending the front stoop of a Jamesian\\r\\r\\nHouse facing south against the Square, the sun\\u2014\\r\\r\\nWho, curveting, his half course not yet run,\\r\\r\\nInfects the earth with crescence;\\r\\r\\nAnd the presence\\r\\r\\nOf process, seen in un-top-hatted,\\r\\r\\nUn-frock-coated burghers and their sons\\r\\r\\nAnd daughters, taking over\\r\\r\\nAll title, right, and interest soever\\r\\r\\nIn this, now their\\r\\r\\nProperty, Washington Square.\\r\\r\\n \\r\\r\\n \\r\\r\\nIII. December 29, 1949\\r\\r\\n \\r\\r\\nThe Hotel Storia ascends\\r\\r\\nAbove me and my new wife; ends\\r\\r\\nEight stories of decline, despair,\\r\\r\\nIron beds and hand-washed underwear\\r\\r\\nAbove us and our leatherette\\r\\r\\nChattels, still grounded on the wet\\r\\r\\nGrey tessellated lobby floor.\\r\\r\\nSoon, through a dingy, numbered door,\\r\\r\\nWe\\u2019ll enter into our new home,\\r\\r\\nProvincials in Imperial Rome\\r\\r\\nTo seek their fortune, or, at least,\\r\\r\\nTo find a job. The wedding feast,\\r\\r\\nDigested and metabolized,\\r\\r\\nDiminishes in idealized\\r\\r\\nGroup photographs, and hard today\\r\\r\\nShunts us together and at bay.\\r\\r\\nOutside the soot-webbed window, sleet\\r\\r\\nScourges the vista of Eighth Street;\\r\\r\\nInside, the radiators clack\\r\\r\\nAnd talk and tell us to go back\\r\\r\\nWhere we came from. A lone pecan\\r\\r\\nFalls from our lunch, a sticky bun,\\r\\r\\nAnd bounces on the trampoline\\r\\r\\nOf the torn bedspread. In the mean\\r\\r\\nDistance of winter, a man sighs,\\r\\r\\nA bedstead creaks, a woman cries.\\r\\r\\n \\r\\r\\n \\r\\r\\nIV. July 14, 1951\\r\\r\\n \\r\\r\\nA summer lull arrives in the West Village,\\r\\r\\nTransmuting houses into silent salvage\\r\\r\\nOf the last century, streets into wreckage\\r\\r\\nUncalled-for by do-gooders who police\\r\\r\\nThe moderniqueness of our ways, patrol\\r\\r\\nThe sanitation of the urban soul.\\r\\r\\nWhat I mean is, devoid of people, all\\r\\r\\nOur dwellings freeze and rust in desuetude,\\r\\r\\nFur over with untenancy, glaze grey\\r\\r\\nWith summer\\u2019s dust and incivility,\\r\\r\\nWith lack of language and engagement, while\\r\\r\\nTheir occupants sport, mutate, and transform\\r\\r\\nThemselves, play at dissembling the god Norm\\r\\r\\nFrom forward bases at Fire Island. But\\u2014\\r\\r\\nException proving rules, dissolving doubt\\u2014\\r\\r\\nYoung Gordon Walker, fledgling editor,\\r\\r\\nMy daylong colleague in the corridors\\r\\r\\nOf Power & Leicht, the trade-book publishers,\\r\\r\\nIs at home to the residue in his\\r\\r\\nAcute apartment in an angle of\\r\\r\\nAbingdon Square. And they\\u2019re all there, the rear-\\r\\r\\nGuard of the garrison of Fort New York:\\r\\r\\nThe skeleton defense of skinny girls\\r\\r\\nWho tap the typewriters of summertime;\\r\\r\\nThe pale male workers who know no time off\\r\\r\\nBecause too recently employed; the old\\r\\r\\nManhattan hands, in patched and gin-stained tweeds;\\r\\r\\nThe writers (Walker\\u2019s one), who see in their\\r\\r\\nCity as desert an oasis of\\r\\r\\nSilence and time to execute their plots\\r\\r\\nAgainst the state of things, but fall a prey\\r\\r\\nTo day succeeding day alone, and call\\r\\r\\nA party to restore themselves to all\\r\\r\\nThe inside jokes of winter, in whose caul\\r\\r\\nPeople click, kiss like billiard balls, and fall,\\r\\r\\nInsensible, into odd pockets. Dense\\r\\r\\nAs gander-feather winter snow, intense\\r\\r\\nAs inextinguishable summer sun\\r\\r\\nAt five o\\u2019clock (which it now is), the noise\\r\\r\\nOf Walker\\u2019s congeries of girls and boys\\r\\r\\nForegathered in their gabbling gratitude\\r\\r\\nStrikes down the stairwell from the altitude\\r\\r\\nOf his wide-open walk-up, beckoning\\r\\r\\nMe, solo, wife gone north, to sickening\\r\\r\\nTop-story heat and talk jackhammering\\r\\r\\nUpon the anvils of all ears. \\u201cChrist, Lou, you\\u2019re here,\\u201d\\r\\r\\nWhoops Walker, topping up a jelly jar\\r\\r\\n(\\u201cCrabapple,\\u201d says the label, still stuck on)\\r\\r\\nWith gin and tonic, a blue liquid smoke\\r\\r\\nThat seeks its level in my unexplored\\r\\r\\nInterior, and sends back a sonar ping\\r\\r\\nTo echo in my head. Two more blue gins.\\r\\r\\nThe sweat that mists my glasses interdicts\\r\\r\\nMy sizing up my interlocutor,\\r\\r\\nWho is, I think, the girl who lives next door,\\r\\r\\nA long-necked, fiddleheaded, celliform\\r\\r\\nGirl cellist propped on an improbably\\r\\r\\nSlim leg. Gin pings are now continuous.\\r\\r\\nThe room swings in its gimbals. In the bath\\r\\r\\nIs silence, blessed, relative, untorn\\r\\r\\nBy the cool drizzle of the bathtub tap,\\r\\r\\nA clear and present invitation. Like\\r\\r\\nA climber conquering K.28,\\r\\r\\nI clamber over the white porcelain\\r\\r\\nRock face, through whitish veils of rubberized\\r\\r\\nShower curtain, and at length, full-dressed, recline\\r\\r\\nIn the encaustic crater, where a fine\\r\\r\\nThread of cold water irrigates my feet,\\r\\r\\nTo sleep, perchance to dream of winter in\\r\\r\\nThe Village, fat with its full complement\\r\\r\\nOf refugees returned to their own turf\\u2014\\r\\r\\nUnspringy as it is\\u2014in a strong surf\\r\\r\\nOf retrogressing lemmings, faces fixed\\r\\r\\nOn the unlovely birthplace of their mixed\\r\\r\\nEmotions, marriages, media, and met-\\r\\r\\nAphors. Lord God of hosts, be with them yet.\\r\\r\\n\",\n          \"\\r\\r\\nEverything that was young went quickly,the way his eyes met mine as soon as wewoke together in a room outside Nanjing,feeling as if all the things that were fallingwould fall and make their thunder, leaveus with the challenge of being happy,all the things that felt given when giftswere not just surprises, but what weknew, what we hoped to take with usto heaven, unbound by faults and sins,not deceived the way we were whenthe end came to what we knew of China,landing me here. I am a wish in the skiesspun out from celestial space to be poor,to be covered with black skin, a feltquilt of a map with only one way to China\\u2009\\u2014\\u2009through pain as big as hogs squealingat killing time on black farms in Alabama\\u2009\\u2014\\u2009the noise of death, the shrill needlethat turns clouds over to rip the airabove the cities where people are youngand all that is given is never taken away.\\r\\r\\n\",\n          \"\\r\\r\\nI dreamt last night\\r\\r\\nthe fright was over, that\\r\\r\\nthe dust came, and then water,   \\r\\r\\nand women and men, together   \\r\\r\\nagain, and all was quiet\\r\\r\\nin the dim moon\\u2019s light.\\r\\r\\nA paean of such patience\\u2014\\r\\r\\nlaughing, laughing at me,   \\r\\r\\nand the days extend over\\r\\r\\nthe earth\\u2019s great cover,\\r\\r\\ngrass, trees, and flower-\\r\\r\\ning season, for no clear reason.\\r\\r\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Poet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3128,\n        \"samples\": [\n          \"Lee Ann Roripaugh\",\n          \"Saadi Youssef\",\n          \"M.L. Smoker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8298,\n        \"samples\": [\n          \"Activities,Jobs & Working,Nature,Landscapes & Pastorals,Social Commentaries,History & Politics,Money & Economics\",\n          \"Living,Death,Sorrow & Grieving,The Body,Nature,Social Commentaries,History & Politics,Race & Ethnicity\",\n          \"Living,Life Choices,The Mind,Youth,Nature,Animals\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-522872b9-22e7-407b-931c-b05f9933d4bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Poem</th>\n",
              "      <th>Poet</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\\r\\r\\n                    Objects Used to Prop...</td>\n",
              "      <td>\\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...</td>\n",
              "      <td>Michelle Menting</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\r\\r\\n                    The New Church\\r\\r\\n...</td>\n",
              "      <td>\\r\\r\\nThe old cupola glinted above the clouds,...</td>\n",
              "      <td>Lucia Cherciu</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\\r\\r\\n                    Look for Me\\r\\r\\n   ...</td>\n",
              "      <td>\\r\\r\\nLook for me under the hood\\r\\r\\nof that ...</td>\n",
              "      <td>Ted Kooser</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\r\\r\\n                    Wild Life\\r\\r\\n     ...</td>\n",
              "      <td>\\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...</td>\n",
              "      <td>Grace Cavalieri</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\\r\\r\\n                    Umbrella\\r\\r\\n      ...</td>\n",
              "      <td>\\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...</td>\n",
              "      <td>Connie Wanek</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-522872b9-22e7-407b-931c-b05f9933d4bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-522872b9-22e7-407b-931c-b05f9933d4bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-522872b9-22e7-407b-931c-b05f9933d4bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b9d8511-a1e6-4fa6-a2c9-49074015e1d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b9d8511-a1e6-4fa6-a2c9-49074015e1d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b9d8511-a1e6-4fa6-a2c9-49074015e1d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0                                              Title  \\\n",
              "0           0  \\r\\r\\n                    Objects Used to Prop...   \n",
              "1           1  \\r\\r\\n                    The New Church\\r\\r\\n...   \n",
              "2           2  \\r\\r\\n                    Look for Me\\r\\r\\n   ...   \n",
              "3           3  \\r\\r\\n                    Wild Life\\r\\r\\n     ...   \n",
              "4           4  \\r\\r\\n                    Umbrella\\r\\r\\n      ...   \n",
              "\n",
              "                                                Poem              Poet Tags  \n",
              "0  \\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...  Michelle Menting       \n",
              "1  \\r\\r\\nThe old cupola glinted above the clouds,...     Lucia Cherciu       \n",
              "2  \\r\\r\\nLook for me under the hood\\r\\r\\nof that ...        Ted Kooser       \n",
              "3  \\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...   Grace Cavalieri       \n",
              "4  \\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...      Connie Wanek       "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PoetryFoundationData.csv')\n",
        "df = df.fillna('')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e1xQ1p5U4xIs"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "special_tokens_dict = {\n",
        "    'bos_token': '',\n",
        "    'eos_token': '',\n",
        "    'pad_token': ''}\n",
        "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PqkNM2nd473z"
      },
      "outputs": [],
      "source": [
        "class Poem_dset(Dataset):\n",
        "  def __init__(self , data , tokenizer , gpt2_type = 'gpt2' , max_len = 1024):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "        # Iterate over data, tokenize each sequence and append its input_id and attention_mask to respective lists\n",
        "    for i in data:\n",
        "      encodings_dict = tokenizer('' + i + '',truncation=True,\n",
        "                                     max_length=max_len,\n",
        "                                     padding='max_length')\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def ___len__ (self):\n",
        "      return len(self.input_ids)\n",
        "\n",
        "    def __get_item__(self , indx):\n",
        "      return self.input_ids[indx] , self.attn_masks[indx]\n",
        "\n",
        "poem_stanza_dataset = Poem_dset(df['Poem'].values, tokenizer, max_len= 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HjHWOvUr72dk"
      },
      "outputs": [],
      "source": [
        "def dset_train(split , data_set):\n",
        "  l =len(data_set)\n",
        "  train_size = int(split * l)\n",
        "  val_data_size = l - train_size\n",
        "  return train_size , val_data_size\n",
        "\n",
        "\n",
        "# function call for splitting the data\n",
        "poem_train_size , poem_validation_size = dset_train(0.8 , df)\n",
        "\n",
        "# to split data randomly for validation and training\n",
        "poem_train_dataset, poem_val_dataset = random_split(df, [poem_train_size, poem_validation_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEgI3He__DyN",
        "outputId": "e622d47d-1329-4aa7-b8e1-c6f0c3f41798"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79bee1914b10>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# initializing the randomizer and pytorch with seed varible\n",
        "random_seed = 73\n",
        "torch.cuda.manual_seed_all(random_seed)\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wq_dcwih_zot"
      },
      "outputs": [],
      "source": [
        "# loading data\n",
        "batchsize  = 2\n",
        "poem_train_data = DataLoader(poem_train_dataset , sampler = RandomSampler(poem_train_dataset) , batch_size = batchsize)\n",
        "poem_validation_data = DataLoader(poem_val_dataset , sampler = SequentialSampler(poem_val_dataset) , batch_size = batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UzWVpnalByPY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# helper function for logging time\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 1e-3\n",
        "eps = 1e-8\n",
        "warmup_steps = 50\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_xPFjDyB6Wf"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Pu0vOJx-B4ng",
        "outputId": "05972dee-89b2-4d78-c5d6-a5fff9cd0c96"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0301604c9605>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoem_train_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2526\u001b[0m             )\n\u001b[1;32m   2527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \"\"\"\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "max_len = 1024\n",
        "configuration = GPT2Config(vocab_size=len(tokenizer), n_positions= max_len).from_pretrained('gpt2', output_hidden_states=True)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
        "total_steps = len(poem_train_data) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_steps)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEBtZhzhDZ29"
      },
      "source": [
        "**TRAINING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-5h9rrMDj-c"
      },
      "outputs": [],
      "source": [
        "#TO HANDLE LOSSES\n",
        "loses = []\n",
        "valid_loss = []\n",
        "start_time = time.time()\n",
        "for i in range(0,epochs):\n",
        "  print(f'Epoch {i+1} of {epochs}')\n",
        "  t0 = time.time()\n",
        "\n",
        "    # Reset the total training loss for this epoch\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  #training the data\n",
        "  for step, batch in enumerate(poem_train_data):\n",
        "    # Move the input ids, labels and masks to the GPU\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        # Clear out the gradients from the previous training step\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass: compute the outputs of the model by passing in the input\n",
        "        outputs = model(b_input_ids, labels=b_labels, attention_mask=b_masks, token_type_ids=None)\n",
        "\n",
        "        # Extract the loss from the outputs\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Extract and accumulate the total loss\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        loses.append(loss.item())\n",
        "\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            print(f\"Step: {step}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Break the loop after 1000 steps.\n",
        "        if step > 1000:\n",
        "            break\n",
        "  avg_train_loss = total_train_loss / len(poem_train_dataloader)\n",
        "\n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')\n",
        "  model.eval()\n",
        "\n",
        "    # Reset the total validation loss\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  # Loop over each batch from the validation data loader\n",
        "  for batch in poem_validation_data:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outputs  = model(b_input_ids, attention_mask=b_masks, labels=b_labels)\n",
        "      loss = outputs[0]\n",
        "      batch_loss = loss.item()\n",
        "      total_eval_loss += batch_loss\n",
        "      valid_loss.append(batch_loss)\n",
        "    avg_val_loss = total_eval_loss / len(poem_val_data)\n",
        "\n",
        "    print(f'Average Validation Loss: {avg_val_loss}')\n",
        "print(f'Total Training Time: {format_time(time.time()-start_time)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),  'poem_stanza_model.pth')"
      ],
      "metadata": {
        "id": "8g-F8ouqjHJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\"\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "poem_stanza_model = model.to(device)\n",
        "\n",
        "prompt = \" I miss home\"\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length=MAX_LEN,\n",
        "                                top_p=0.95,\n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "print(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        ""
      ],
      "metadata": {
        "id": "9oCkTbHcjrAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1LKTA_zrO9drWEKNNi65M4cGagNtPQQm-",
      "authorship_tag": "ABX9TyM9bAzxG7JaraIjzct5GbS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}